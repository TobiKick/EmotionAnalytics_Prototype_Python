{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "# import statements\n",
    "import sys\n",
    "from PyQt5.QtCore import *\n",
    "from PyQt5.QtGui import *\n",
    "from PyQt5.QtWidgets import *\n",
    "from PyQt5 import QtWidgets, uic, QtCore, QtGui\n",
    "from PyQt5.QtCore import QObject, pyqtSignal\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pygetwindow as gw\n",
    "\n",
    "# for reading from an window\n",
    "import cv2\n",
    "from PIL import ImageGrab, Image\n",
    "from numpy import asarray\n",
    "import win32api\n",
    "import win32gui\n",
    "import win32con\n",
    "import numpy as np\n",
    "import pywintypes\n",
    "\n",
    "#For local CPU usage:\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "from keras_vggface.utils import preprocess_input\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from keras.models import load_model, Sequential, Model\n",
    "from keras.layers import Dense, BatchNormalization, Dropout, Flatten\n",
    "from keras.backend import clear_session, set_session\n",
    "import tensorflow as tf\n",
    "\n",
    "tf_version = str(tf.__version__)\n",
    "\n",
    "# VARIABLES\n",
    "IPYTHON = True\n",
    "IMAGE_HEIGHT = 224\n",
    "IMAGE_WIDTH = 224\n",
    "\n",
    "INTERVAL_SECONDS = 3  ## Interval seconds between each time an emotion recognition output is produced\n",
    "IMAGES_PER_INTERVAL = 6\n",
    "INTEREST_FRAMES = 20\n",
    "\n",
    "LAYERS_TRAINABLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app_prototype - Jupyter Notebook - Google Chrome\n",
      "Carlos Vives - No Te Vayas\n",
      "*AFEW-VA_SSH - Blocco note di Windows\n",
      "Fotocamera\n",
      "Fotocamera\n",
      "app_prototype - Jupyter Notebook - Google Chrome\n",
      "['app_prototype - Jupyter Notebook - Google Chrome', 'Carlos Vives - No Te Vayas', '*AFEW-VA_SSH - Blocco note di Windows', 'Fotocamera', 'Fotocamera', 'app_prototype - Jupyter Notebook - Google Chrome']\n"
     ]
    }
   ],
   "source": [
    "def getWindowNames():\n",
    "    visibleWindows = []   \n",
    "    \n",
    "    #if gw.getWindowsWithTitle('Fotocamera'):\n",
    "    #    visibleWindows.append('Fotocamera')\n",
    "    \n",
    "    for i in gw.getAllTitles():        \n",
    "        notepadWindow = gw.getWindowsWithTitle(i)[0]\n",
    "        \n",
    "        if notepadWindow.isMinimized or notepadWindow.isMaximized:\n",
    "            print(notepadWindow.title)\n",
    "            visibleWindows.append(notepadWindow.title)\n",
    "    \n",
    "    return visibleWindows\n",
    "\n",
    "\n",
    "print(getWindowNames())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_5\n",
      "conv1_1\n",
      "conv1_2\n",
      "pool1\n",
      "conv2_1\n",
      "conv2_2\n",
      "pool2\n",
      "conv3_1\n",
      "conv3_2\n",
      "conv3_3\n",
      "pool3\n",
      "conv4_1\n",
      "conv4_2\n",
      "conv4_3\n",
      "pool4\n",
      "conv5_1\n",
      "conv5_2\n",
      "conv5_3\n",
      "pool5\n"
     ]
    }
   ],
   "source": [
    "def custom_vgg_model():\n",
    "    vgg_model = VGGFace(include_top=False, input_shape=(224, 224, 3))\n",
    "    \n",
    "    for layer in vgg_model.layers: \n",
    "        layer.trainable = LAYERS_TRAINABLE\n",
    "        print(layer.name)\n",
    "    \n",
    "    last_layer = vgg_model.get_layer('pool5').output    \n",
    "    x = Flatten(name='flatten')(last_layer)\n",
    "    # x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(16, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    out1 = Dense(1, activation='tanh', name='out1')(x)\n",
    "    out2 = Dense(1, activation='tanh', name='out2')(x)\n",
    "    custom_vgg_model = Model(inputs= vgg_model.input, outputs= [out1, out2])\n",
    "    \n",
    "    return custom_vgg_model\n",
    "\n",
    "model_top = custom_vgg_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(tf_version[0])\n",
    "if tf_version[0] == \"1\":  # tensorflow 1.x\n",
    "    ## setting Keras sessions for each of the pretrained networks\n",
    "    sess = tf.Session()\n",
    "    graph = tf.get_default_graph()\n",
    "    set_session(sess)\n",
    "    detector = MTCNN()\n",
    "\n",
    "    ## Second Network\n",
    "    # sess2 = tf.Session()\n",
    "    # graph = tf.get_default_graph()\n",
    "    # set_session(sess2)\n",
    "    # model_VGGFace = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
    "\n",
    "    # Third Network\n",
    "    sess3 = tf.Session()\n",
    "    graph = tf.get_default_graph()\n",
    "    set_session(sess3)\n",
    "    model_top.load_weights(\"model_best.h5\")\n",
    "    \n",
    "    \n",
    "elif tf_version[0] == \"2\": # tensorflow 2.x\n",
    "    print(\"Tensorflow version 2 is not compatible. Please use tensorflow version 1.x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces(image):\n",
    "    global sess\n",
    "    global graph\n",
    "    with graph.as_default():\n",
    "        set_session(sess)\n",
    "        faces = detector.detect_faces(image)\n",
    "        return np.array(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face_from_image(image, required_size=(IMAGE_HEIGHT, IMAGE_WIDTH)):\n",
    "    face = detect_faces(image) # content of face is a python dict\n",
    "\n",
    "    if len(face) == 0:\n",
    "        return []\n",
    "    else:\n",
    "        # extract the bounding box from the requested face\n",
    "        box = np.asarray(face[0]['box'])\n",
    "        box[box < 0] = 0\n",
    "        x1, y1, width, height =  box\n",
    "\n",
    "        x2, y2 = x1 + width, y1 + height\n",
    "        # extract the face\n",
    "        face_boundary = image[y1:y2, x1:x2]\n",
    "\n",
    "        # resize pixels to the model size\n",
    "        face_image = Image.fromarray(face_boundary)\n",
    "        face_image = face_image.resize(required_size)\n",
    "        face_array = asarray(face_image)\n",
    "        return face_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_face_embedding(face):\n",
    "#    samples = asarray(face, 'float32')\n",
    "#    # prepare the data for the model\n",
    "#    samples = preprocess_input(samples, version=2)\n",
    "#    \n",
    "#    global sess2\n",
    "#    global graph\n",
    "#    with graph.as_default():\n",
    "#        set_session(sess2)\n",
    "#        output = model_VGGFace.predict(samples)\n",
    "#        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.5  # range of values is from -1 to +1\n",
    "emotion_scores_list = []\n",
    "\n",
    "def identify_interest(val):\n",
    "    positive = 0\n",
    "    negative = 0\n",
    "    neutral = 0\n",
    "\n",
    "    for i in emotion_scores_list:\n",
    "        if i > (THRESHOLD/2):\n",
    "            positive = positive + 1\n",
    "        elif i < (-THRESHOLD/2):\n",
    "            negative = negative + 1\n",
    "        else:\n",
    "            neutral = neutral + 1\n",
    "\n",
    "    print(positive)\n",
    "    print(negative)\n",
    "    print(neutral)\n",
    "\n",
    "    if neutral > (positive + negative):\n",
    "        return \"-\"\n",
    "    elif positive/2 > negative:\n",
    "        return \"VERY INTERESTED\"\n",
    "    elif positive > negative:\n",
    "        return \"INTERESTED\"\n",
    "    else:\n",
    "        return \"Not interested!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_prediction(path):\n",
    "    #converting image to RGB color and save it\n",
    "    img = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    #detect face in image, crop it then resize it\n",
    "    face = extract_face_from_image(img)\n",
    "\n",
    "    if face == []:\n",
    "        return None, None\n",
    "    else:\n",
    "        print(\"Face detected\")\n",
    "        if face.ndim == 3:\n",
    "            face = face.reshape((1, face.shape[0], face.shape[1], face.shape[2]))\n",
    "        face = np.array(face)\n",
    "        \n",
    "        clear_session()\n",
    "        global sess3\n",
    "        global graph\n",
    "        with graph.as_default():\n",
    "            set_session(sess3)\n",
    "            out1, out2 = model_top.predict(face) #make prediction and display the result\n",
    "            val = out1[0][0] * 10\n",
    "            ar = out2[0][0] * 10\n",
    "            print(\"result: \" + str(val) + \", \" + str(ar))\n",
    "            return val, ar    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ProcessStream - Tasks:\n",
    "         Task 1: Use Multithreading for GUI + Processing\n",
    "         Task 2: Get pixels as an Input Stream (using OpenCV)\n",
    "         https://theailearner.com/2018/10/16/recording-a-specific-window-using-opencv-python/\n",
    "         Task 3: Preprocessing & Landmark detection\n",
    "         Task 4: Read in Python Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessStream(QThread):   \n",
    "    output = pyqtSignal(object)\n",
    "    def __init__(self):\n",
    "        super(ProcessStream, self).__init__()\n",
    "        self.active = True\n",
    "\n",
    "    def run(self):\n",
    "        # Task 1: Use Multithreading ???   for GUI + Input Stream\n",
    "        # Task 2: Get pixels as an Input Stream (using OpenCV)\n",
    "        # Task 3: Preprocessing & Landmark detection\n",
    "        # Task 4: Read in Python Model\n",
    "        image = ImageGrab.grab()\n",
    "        height,width,channel = np.array(image).shape\n",
    "\n",
    "        out = cv2.VideoWriter('video.avi',cv2.VideoWriter_fourcc(*'DIVX'), 5, (width,height))\n",
    "        \n",
    "        val_list = []\n",
    "        arr_list = []\n",
    "        i = 0\n",
    "        \n",
    "        while self.active == True:\n",
    "            # image = ImageGrab.grab(rect)\n",
    "            image = ImageGrab.grab()\n",
    "            out.write(cv2.cvtColor(np.array(image), cv2.COLOR_BGR2RGB))\n",
    "            \n",
    "            imgUMat = np.float32(image)\n",
    "            cv2.imwrite(\"test.jpg\", imgUMat)\n",
    "\n",
    "            val, arr = return_prediction(\"test.jpg\")\n",
    "            if val != None:\n",
    "                val_list.append(val)\n",
    "                arr_list.append(arr)\n",
    "                if len(val_list) > IMAGES_PER_INTERVAL:\n",
    "                    val_list.pop(0)\n",
    "                    arr_list.pop(0)\n",
    "                \n",
    "                emotion_scores_list.append(val)\n",
    "                if len(emotion_scores_list) > INTEREST_FRAMES:\n",
    "                    emotion_scores_list.pop(0)\n",
    "                \n",
    "                i = i + 1\n",
    "                if i % INTERVAL_SECONDS == 0:\n",
    "                    interest = identify_interest(val)\n",
    "                    print(\"Interest: \" + str(interest))\n",
    "                \n",
    "                    valence = sum(val_list) / len(val_list)\n",
    "                    arousal = sum(arr_list) / len(arr_list)\n",
    "                    now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                    result = str(now) + \"   Valence: \" + str(round(valence, 4)) + \"\\n\" + str(now) + \"   Arousal: \" + str(round(arousal, 4)) + \"\\n\" + \"Conclusion: \" + str(interest)\n",
    "                    self.output.emit(result)\n",
    "                \n",
    "            time.sleep(int(INTERVAL_SECONDS/IMAGES_PER_INTERVAL))\n",
    "        out.release()\n",
    "        \n",
    "    def stop(self):\n",
    "        print(\"STOP Thread\")\n",
    "        self.active = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class CreateContent(threading.Thread):\n",
    "#    def dynamicContentCreation():\n",
    "        # Last step in Prototype\n",
    "        # Speech Recognition ( Speech -> to -> Text )\n",
    "        # Make us of a 'faked' chat-bot (decision tree)\n",
    "#        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytics got started!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tobias\\Projects\\EmotionAnalytics_Prototype_Python\\venv\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face detected\n",
      "[[[[27 45 47]\n",
      "   [30 48 50]\n",
      "   [34 52 54]\n",
      "   ...\n",
      "   [25 34 39]\n",
      "   [25 36 40]\n",
      "   [28 39 43]]\n",
      "\n",
      "  [[26 44 46]\n",
      "   [30 48 50]\n",
      "   [33 50 53]\n",
      "   ...\n",
      "   [24 33 38]\n",
      "   [24 34 39]\n",
      "   [25 35 40]]\n",
      "\n",
      "  [[29 47 49]\n",
      "   [32 50 52]\n",
      "   [31 49 51]\n",
      "   ...\n",
      "   [21 30 35]\n",
      "   [22 31 36]\n",
      "   [25 34 39]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[23 42 38]\n",
      "   [25 44 40]\n",
      "   [27 46 44]\n",
      "   ...\n",
      "   [20 30 29]\n",
      "   [26 36 35]\n",
      "   [26 36 35]]\n",
      "\n",
      "  [[21 41 38]\n",
      "   [22 41 38]\n",
      "   [24 44 42]\n",
      "   ...\n",
      "   [17 27 26]\n",
      "   [23 34 33]\n",
      "   [25 36 34]]\n",
      "\n",
      "  [[22 42 41]\n",
      "   [22 42 41]\n",
      "   [23 43 41]\n",
      "   ...\n",
      "   [20 32 30]\n",
      "   [24 38 35]\n",
      "   [23 37 35]]]]\n",
      "result: 0.600103847682476, 3.9259663224220276\n",
      "Face detected\n",
      "[[[[ 43  64  62]\n",
      "   [ 42  63  60]\n",
      "   [ 40  61  56]\n",
      "   ...\n",
      "   [ 13  20  20]\n",
      "   [ 15  22  22]\n",
      "   [ 16  23  23]]\n",
      "\n",
      "  [[ 41  61  59]\n",
      "   [ 43  62  59]\n",
      "   [ 45  64  60]\n",
      "   ...\n",
      "   [ 13  21  20]\n",
      "   [ 14  23  22]\n",
      "   [ 14  22  24]]\n",
      "\n",
      "  [[ 41  62  57]\n",
      "   [ 43  62  58]\n",
      "   [ 46  64  60]\n",
      "   ...\n",
      "   [ 19  25  27]\n",
      "   [ 18  24  26]\n",
      "   [ 19  25  28]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 22  34  34]\n",
      "   [ 22  34  33]\n",
      "   [ 23  35  34]\n",
      "   ...\n",
      "   [ 27  37  33]\n",
      "   [ 28  37  32]\n",
      "   [ 28  37  29]]\n",
      "\n",
      "  [[131 112  80]\n",
      "   [132 113  79]\n",
      "   [132 113  79]\n",
      "   ...\n",
      "   [135 114  80]\n",
      "   [135 115  79]\n",
      "   [134 114  77]]\n",
      "\n",
      "  [[244 193 129]\n",
      "   [245 194 130]\n",
      "   [245 195 131]\n",
      "   ...\n",
      "   [245 193 132]\n",
      "   [245 194 130]\n",
      "   [245 194 129]]]]\n",
      "result: -0.6649013608694077, 6.392804980278015\n",
      "Face detected\n",
      "[[[[50 89 86]\n",
      "   [50 89 85]\n",
      "   [50 88 84]\n",
      "   ...\n",
      "   [45 48 59]\n",
      "   [38 42 52]\n",
      "   [35 39 47]]\n",
      "\n",
      "  [[52 91 86]\n",
      "   [50 88 84]\n",
      "   [51 87 83]\n",
      "   ...\n",
      "   [46 49 63]\n",
      "   [40 42 55]\n",
      "   [37 41 51]]\n",
      "\n",
      "  [[54 90 86]\n",
      "   [53 89 85]\n",
      "   [52 88 84]\n",
      "   ...\n",
      "   [46 47 65]\n",
      "   [42 43 59]\n",
      "   [38 42 54]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[49 83 82]\n",
      "   [47 82 81]\n",
      "   [46 82 80]\n",
      "   ...\n",
      "   [55 75 73]\n",
      "   [56 76 74]\n",
      "   [52 74 71]]\n",
      "\n",
      "  [[49 84 82]\n",
      "   [47 84 81]\n",
      "   [46 83 81]\n",
      "   ...\n",
      "   [54 74 73]\n",
      "   [54 75 74]\n",
      "   [55 75 73]]\n",
      "\n",
      "  [[46 84 82]\n",
      "   [44 84 81]\n",
      "   [44 84 80]\n",
      "   ...\n",
      "   [52 74 72]\n",
      "   [52 76 73]\n",
      "   [55 76 74]]]]\n",
      "result: -0.7288523763418198, 2.4665889143943787\n",
      "1\n",
      "2\n",
      "0\n",
      "Interest: Not interested!\n",
      "Face detected\n",
      "[[[[ 48  86  83]\n",
      "   [ 47  83  81]\n",
      "   [ 47  83  81]\n",
      "   ...\n",
      "   [ 22  25  35]\n",
      "   [ 24  27  37]\n",
      "   [ 25  29  38]]\n",
      "\n",
      "  [[ 48  84  82]\n",
      "   [ 49  85  83]\n",
      "   [ 48  84  81]\n",
      "   ...\n",
      "   [ 21  26  37]\n",
      "   [ 23  27  38]\n",
      "   [ 23  27  39]]\n",
      "\n",
      "  [[ 49  84  81]\n",
      "   [ 51  86  82]\n",
      "   [ 51  86  82]\n",
      "   ...\n",
      "   [ 24  28  40]\n",
      "   [ 23  27  39]\n",
      "   [ 20  26  38]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[119 139 161]\n",
      "   [121 139 160]\n",
      "   [124 142 162]\n",
      "   ...\n",
      "   [ 43  74  73]\n",
      "   [ 40  72  70]\n",
      "   [ 38  70  69]]\n",
      "\n",
      "  [[115 134 158]\n",
      "   [121 138 160]\n",
      "   [123 140 163]\n",
      "   ...\n",
      "   [ 41  73  72]\n",
      "   [ 39  72  71]\n",
      "   [ 40  71  70]]\n",
      "\n",
      "  [[110 128 152]\n",
      "   [115 131 154]\n",
      "   [118 134 157]\n",
      "   ...\n",
      "   [ 43  71  72]\n",
      "   [ 42  72  72]\n",
      "   [ 43  72  70]]]]\n",
      "result: -0.3788125142455101, 1.7451432347297668\n",
      "Face detected\n",
      "[[[[60 84 68]\n",
      "   [59 82 66]\n",
      "   [61 84 68]\n",
      "   ...\n",
      "   [42 40 42]\n",
      "   [36 34 36]\n",
      "   [31 29 30]]\n",
      "\n",
      "  [[62 85 69]\n",
      "   [60 83 67]\n",
      "   [62 84 69]\n",
      "   ...\n",
      "   [40 38 41]\n",
      "   [37 35 39]\n",
      "   [36 34 35]]\n",
      "\n",
      "  [[63 84 69]\n",
      "   [64 84 69]\n",
      "   [65 84 70]\n",
      "   ...\n",
      "   [40 40 42]\n",
      "   [37 37 39]\n",
      "   [38 36 39]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[50 70 79]\n",
      "   [50 70 79]\n",
      "   [49 72 80]\n",
      "   ...\n",
      "   [59 71 61]\n",
      "   [57 69 59]\n",
      "   [58 71 59]]\n",
      "\n",
      "  [[50 71 78]\n",
      "   [49 72 77]\n",
      "   [49 73 78]\n",
      "   ...\n",
      "   [59 71 61]\n",
      "   [58 70 59]\n",
      "   [60 72 60]]\n",
      "\n",
      "  [[49 72 77]\n",
      "   [47 71 74]\n",
      "   [47 71 73]\n",
      "   ...\n",
      "   [57 69 59]\n",
      "   [59 72 60]\n",
      "   [60 74 61]]]]\n",
      "result: -5.640226602554321, 2.1750834584236145\n",
      "Face detected\n",
      "[[[[ 70  88  61]\n",
      "   [ 70  88  60]\n",
      "   [ 70  86  61]\n",
      "   ...\n",
      "   [ 34  31  24]\n",
      "   [ 32  29  22]\n",
      "   [ 30  27  20]]\n",
      "\n",
      "  [[ 72  87  61]\n",
      "   [ 71  86  62]\n",
      "   [ 70  85  62]\n",
      "   ...\n",
      "   [ 36  33  26]\n",
      "   [ 34  31  24]\n",
      "   [ 32  29  22]]\n",
      "\n",
      "  [[ 72  86  61]\n",
      "   [ 72  86  61]\n",
      "   [ 70  84  60]\n",
      "   ...\n",
      "   [ 35  32  26]\n",
      "   [ 36  33  26]\n",
      "   [ 37  34  27]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[108 122 125]\n",
      "   [108 119 126]\n",
      "   [108 118 123]\n",
      "   ...\n",
      "   [ 32  39  23]\n",
      "   [ 30  38  21]\n",
      "   [ 30  39  24]]\n",
      "\n",
      "  [[109 120 122]\n",
      "   [108 119 123]\n",
      "   [116 126 128]\n",
      "   ...\n",
      "   [ 31  36  19]\n",
      "   [ 29  34  16]\n",
      "   [ 34  40  24]]\n",
      "\n",
      "  [[116 127 128]\n",
      "   [115 126 127]\n",
      "   [118 128 130]\n",
      "   ...\n",
      "   [ 31  34  15]\n",
      "   [ 34  38  19]\n",
      "   [ 35  39  23]]]]\n",
      "result: -3.6901336908340454, 2.9746034741401672\n",
      "1\n",
      "5\n",
      "0\n",
      "Interest: Not interested!\n",
      "Face detected\n",
      "[[[[ 70  86  64]\n",
      "   [ 67  83  61]\n",
      "   [ 68  84  61]\n",
      "   ...\n",
      "   [ 39  34  28]\n",
      "   [ 39  35  28]\n",
      "   [ 37  34  29]]\n",
      "\n",
      "  [[ 66  84  62]\n",
      "   [ 65  84  60]\n",
      "   [ 66  84  60]\n",
      "   ...\n",
      "   [ 46  44  37]\n",
      "   [ 46  44  38]\n",
      "   [ 45  45  40]]\n",
      "\n",
      "  [[ 65  85  60]\n",
      "   [ 64  86  58]\n",
      "   [ 65  87  59]\n",
      "   ...\n",
      "   [ 43  43  38]\n",
      "   [ 43  44  38]\n",
      "   [ 44  45  40]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 88 106 111]\n",
      "   [ 89 106 111]\n",
      "   [ 92 107 113]\n",
      "   ...\n",
      "   [ 60  71  60]\n",
      "   [ 57  70  58]\n",
      "   [ 52  71  55]]\n",
      "\n",
      "  [[103 121 124]\n",
      "   [ 99 115 119]\n",
      "   [102 117 121]\n",
      "   ...\n",
      "   [ 55  68  56]\n",
      "   [ 54  68  53]\n",
      "   [ 53  71  55]]\n",
      "\n",
      "  [[109 124 127]\n",
      "   [105 120 123]\n",
      "   [107 121 124]\n",
      "   ...\n",
      "   [ 51  67  54]\n",
      "   [ 51  69  53]\n",
      "   [ 55  72  54]]]]\n",
      "result: -2.6253601908683777, 2.305930405855179\n",
      "Face detected\n",
      "[[[[ 70  84  61]\n",
      "   [ 70  85  62]\n",
      "   [ 68  83  61]\n",
      "   ...\n",
      "   [ 44  39  33]\n",
      "   [ 43  39  31]\n",
      "   [ 39  36  28]]\n",
      "\n",
      "  [[ 70  84  59]\n",
      "   [ 71  85  62]\n",
      "   [ 72  85  62]\n",
      "   ...\n",
      "   [ 43  40  33]\n",
      "   [ 42  39  32]\n",
      "   [ 38  36  29]]\n",
      "\n",
      "  [[ 69  83  60]\n",
      "   [ 69  82  59]\n",
      "   [ 71  83  61]\n",
      "   ...\n",
      "   [ 47  44  37]\n",
      "   [ 44  41  34]\n",
      "   [ 39  39  31]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 86  96 105]\n",
      "   [ 87  97 107]\n",
      "   [ 88  98 108]\n",
      "   ...\n",
      "   [ 57  68  51]\n",
      "   [ 58  71  53]\n",
      "   [ 55  66  50]]\n",
      "\n",
      "  [[ 99 109 118]\n",
      "   [ 97 107 117]\n",
      "   [ 96 106 117]\n",
      "   ...\n",
      "   [ 59  70  53]\n",
      "   [ 59  70  53]\n",
      "   [ 59  71  53]]\n",
      "\n",
      "  [[104 116 124]\n",
      "   [ 99 111 120]\n",
      "   [ 96 108 118]\n",
      "   ...\n",
      "   [ 59  71  51]\n",
      "   [ 60  71  51]\n",
      "   [ 59  71  51]]]]\n",
      "result: -2.180013209581375, 3.5225918889045715\n",
      "Face detected\n",
      "[[[[ 72  84  64]\n",
      "   [ 71  83  63]\n",
      "   [ 69  83  62]\n",
      "   ...\n",
      "   [ 42  40  31]\n",
      "   [ 43  40  32]\n",
      "   [ 44  40  31]]\n",
      "\n",
      "  [[ 71  86  65]\n",
      "   [ 68  81  61]\n",
      "   [ 67  80  60]\n",
      "   ...\n",
      "   [ 42  39  32]\n",
      "   [ 44  41  34]\n",
      "   [ 45  40  33]]\n",
      "\n",
      "  [[ 71  86  65]\n",
      "   [ 69  84  63]\n",
      "   [ 68  83  62]\n",
      "   ...\n",
      "   [ 46  41  37]\n",
      "   [ 48  43  37]\n",
      "   [ 48  43  37]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 70  84  92]\n",
      "   [ 67  80  89]\n",
      "   [ 72  87  96]\n",
      "   ...\n",
      "   [ 37  41  27]\n",
      "   [ 51  57  41]\n",
      "   [ 63  71  54]]\n",
      "\n",
      "  [[ 80  95 102]\n",
      "   [ 75  88  96]\n",
      "   [ 76  91  99]\n",
      "   ...\n",
      "   [ 37  43  31]\n",
      "   [ 51  58  45]\n",
      "   [ 60  69  54]]\n",
      "\n",
      "  [[ 89 102 110]\n",
      "   [ 84  98 106]\n",
      "   [ 81  97 104]\n",
      "   ...\n",
      "   [ 44  52  39]\n",
      "   [ 58  67  54]\n",
      "   [ 63  74  60]]]]\n",
      "result: -1.6742125153541565, 3.7030988931655884\n",
      "1\n",
      "8\n",
      "0\n",
      "Interest: Not interested!\n",
      "Face detected\n",
      "[[[[ 69  86  60]\n",
      "   [ 69  87  61]\n",
      "   [ 68  85  59]\n",
      "   ...\n",
      "   [ 42  32  30]\n",
      "   [ 43  34  32]\n",
      "   [ 38  31  26]]\n",
      "\n",
      "  [[ 65  84  59]\n",
      "   [ 67  86  61]\n",
      "   [ 66  85  59]\n",
      "   ...\n",
      "   [ 45  35  33]\n",
      "   [ 47  38  35]\n",
      "   [ 37  30  24]]\n",
      "\n",
      "  [[ 64  85  60]\n",
      "   [ 66  86  61]\n",
      "   [ 65  85  60]\n",
      "   ...\n",
      "   [ 45  38  35]\n",
      "   [ 47  40  36]\n",
      "   [ 42  35  29]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 74  84  96]\n",
      "   [ 74  85  97]\n",
      "   [ 77  86  99]\n",
      "   ...\n",
      "   [ 44  53  36]\n",
      "   [ 66  76  59]\n",
      "   [ 65  76  59]]\n",
      "\n",
      "  [[ 82  92 103]\n",
      "   [ 75  85  96]\n",
      "   [ 75  83  95]\n",
      "   ...\n",
      "   [ 46  55  38]\n",
      "   [ 63  72  55]\n",
      "   [ 66  75  58]]\n",
      "\n",
      "  [[ 87  97 107]\n",
      "   [ 79  89  99]\n",
      "   [ 78  86  97]\n",
      "   ...\n",
      "   [ 55  62  47]\n",
      "   [ 61  68  52]\n",
      "   [ 59  68  51]]]]\n",
      "result: -1.0971439629793167, 4.704672992229462\n",
      "Face detected\n",
      "[[[[ 65  82  56]\n",
      "   [ 64  83  58]\n",
      "   [ 66  85  62]\n",
      "   ...\n",
      "   [ 49  43  35]\n",
      "   [ 52  45  37]\n",
      "   [ 50  43  35]]\n",
      "\n",
      "  [[ 67  86  61]\n",
      "   [ 65  85  61]\n",
      "   [ 65  85  63]\n",
      "   ...\n",
      "   [ 46  43  37]\n",
      "   [ 47  43  35]\n",
      "   [ 48  42  35]]\n",
      "\n",
      "  [[ 65  86  61]\n",
      "   [ 64  86  63]\n",
      "   [ 63  85  64]\n",
      "   ...\n",
      "   [ 47  45  40]\n",
      "   [ 48  45  40]\n",
      "   [ 45  43  36]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 87 100 108]\n",
      "   [ 80  93 100]\n",
      "   [ 82  93  99]\n",
      "   ...\n",
      "   [ 27  39  24]\n",
      "   [ 36  47  31]\n",
      "   [ 51  60  44]]\n",
      "\n",
      "  [[ 92 107 114]\n",
      "   [ 90 103 111]\n",
      "   [ 92 102 111]\n",
      "   ...\n",
      "   [ 29  40  26]\n",
      "   [ 42  53  38]\n",
      "   [ 56  65  50]]\n",
      "\n",
      "  [[ 95 110 117]\n",
      "   [ 98 112 119]\n",
      "   [ 98 108 118]\n",
      "   ...\n",
      "   [ 33  42  28]\n",
      "   [ 48  57  44]\n",
      "   [ 62  70  55]]]]\n",
      "result: -0.9727165848016739, 3.5494330525398254\n",
      "Face detected\n",
      "[[[[ 64  85  66]\n",
      "   [ 62  83  64]\n",
      "   [ 63  84  65]\n",
      "   ...\n",
      "   [ 35  30  26]\n",
      "   [ 38  33  29]\n",
      "   [ 40  35  31]]\n",
      "\n",
      "  [[ 66  85  66]\n",
      "   [ 64  83  64]\n",
      "   [ 63  82  63]\n",
      "   ...\n",
      "   [ 39  35  31]\n",
      "   [ 43  38  35]\n",
      "   [ 44  39  36]]\n",
      "\n",
      "  [[ 66  85  65]\n",
      "   [ 65  83  63]\n",
      "   [ 64  82  63]\n",
      "   ...\n",
      "   [ 42  38  36]\n",
      "   [ 44  39  36]\n",
      "   [ 44  39  36]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 83  94 101]\n",
      "   [ 82  93 101]\n",
      "   [ 80  91  97]\n",
      "   ...\n",
      "   [ 56  65  47]\n",
      "   [ 61  71  54]\n",
      "   [ 57  68  51]]\n",
      "\n",
      "  [[ 90 100 106]\n",
      "   [ 91  99 105]\n",
      "   [ 84  92  97]\n",
      "   ...\n",
      "   [ 55  65  45]\n",
      "   [ 57  66  48]\n",
      "   [ 53  64  46]]\n",
      "\n",
      "  [[101 110 115]\n",
      "   [ 96 106 108]\n",
      "   [ 84  94  96]\n",
      "   ...\n",
      "   [ 53  61  43]\n",
      "   [ 56  64  45]\n",
      "   [ 58  68  48]]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: -0.5460640043020248, 4.16499525308609\n",
      "1\n",
      "11\n",
      "0\n",
      "Interest: Not interested!\n",
      "Face detected\n",
      "[[[[ 67  84  58]\n",
      "   [ 69  85  59]\n",
      "   [ 70  86  60]\n",
      "   ...\n",
      "   [ 41  38  34]\n",
      "   [ 44  42  37]\n",
      "   [ 41  41  34]]\n",
      "\n",
      "  [[ 67  86  58]\n",
      "   [ 72  88  60]\n",
      "   [ 73  89  63]\n",
      "   ...\n",
      "   [ 42  41  37]\n",
      "   [ 44  43  39]\n",
      "   [ 43  42  38]]\n",
      "\n",
      "  [[ 70  88  62]\n",
      "   [ 71  89  63]\n",
      "   [ 71  89  63]\n",
      "   ...\n",
      "   [ 44  43  39]\n",
      "   [ 45  46  41]\n",
      "   [ 44  45  40]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 78  90  98]\n",
      "   [ 77  90  98]\n",
      "   [ 74  87  94]\n",
      "   ...\n",
      "   [ 45  49  37]\n",
      "   [ 66  69  58]\n",
      "   [ 67  72  60]]\n",
      "\n",
      "  [[ 90 101 107]\n",
      "   [ 86 100 106]\n",
      "   [ 84  97 102]\n",
      "   ...\n",
      "   [ 46  53  38]\n",
      "   [ 66  72  58]\n",
      "   [ 64  72  57]]\n",
      "\n",
      "  [[ 98 110 116]\n",
      "   [ 92 105 111]\n",
      "   [ 90 103 109]\n",
      "   ...\n",
      "   [ 49  58  40]\n",
      "   [ 63  72  56]\n",
      "   [ 62  74  56]]]]\n",
      "result: -0.6362631171941757, 4.037115275859833\n",
      "Face detected\n",
      "[[[[ 71  85  59]\n",
      "   [ 72  86  60]\n",
      "   [ 72  86  60]\n",
      "   ...\n",
      "   [ 36  34  22]\n",
      "   [ 37  35  23]\n",
      "   [ 39  37  25]]\n",
      "\n",
      "  [[ 70  84  58]\n",
      "   [ 71  85  59]\n",
      "   [ 71  85  59]\n",
      "   ...\n",
      "   [ 33  31  20]\n",
      "   [ 36  33  23]\n",
      "   [ 39  36  26]]\n",
      "\n",
      "  [[ 68  83  57]\n",
      "   [ 68  82  56]\n",
      "   [ 67  82  56]\n",
      "   ...\n",
      "   [ 35  31  23]\n",
      "   [ 36  33  24]\n",
      "   [ 36  32  24]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 80  96 101]\n",
      "   [ 77  91  97]\n",
      "   [ 81  93 100]\n",
      "   ...\n",
      "   [ 42  48  34]\n",
      "   [ 63  69  54]\n",
      "   [ 63  71  55]]\n",
      "\n",
      "  [[ 91 103 109]\n",
      "   [ 88 100 105]\n",
      "   [ 88  98 104]\n",
      "   ...\n",
      "   [ 49  56  44]\n",
      "   [ 61  70  57]\n",
      "   [ 56  67  52]]\n",
      "\n",
      "  [[ 99 109 115]\n",
      "   [ 96 106 110]\n",
      "   [ 94 102 107]\n",
      "   ...\n",
      "   [ 59  67  56]\n",
      "   [ 58  70  58]\n",
      "   [ 53  66  53]]]]\n",
      "result: 0.38335327059030533, 4.708991646766663\n",
      "Face detected\n",
      "[[[[65 83 57]\n",
      "   [65 83 57]\n",
      "   [66 84 58]\n",
      "   ...\n",
      "   [24 23 19]\n",
      "   [25 25 22]\n",
      "   [26 26 24]]\n",
      "\n",
      "  [[65 84 56]\n",
      "   [65 84 56]\n",
      "   [64 83 56]\n",
      "   ...\n",
      "   [27 26 22]\n",
      "   [26 26 23]\n",
      "   [26 26 24]]\n",
      "\n",
      "  [[65 84 56]\n",
      "   [65 84 57]\n",
      "   [65 85 57]\n",
      "   ...\n",
      "   [34 30 27]\n",
      "   [32 28 25]\n",
      "   [31 27 24]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[60 66 80]\n",
      "   [59 65 77]\n",
      "   [60 64 76]\n",
      "   ...\n",
      "   [54 67 47]\n",
      "   [55 69 50]\n",
      "   [54 69 50]]\n",
      "\n",
      "  [[64 68 80]\n",
      "   [62 66 77]\n",
      "   [63 67 78]\n",
      "   ...\n",
      "   [53 66 46]\n",
      "   [55 69 50]\n",
      "   [54 71 52]]\n",
      "\n",
      "  [[58 62 73]\n",
      "   [57 61 70]\n",
      "   [61 65 74]\n",
      "   ...\n",
      "   [57 70 50]\n",
      "   [58 72 52]\n",
      "   [58 73 53]]]]\n",
      "result: -0.04420400597155094, 3.027390241622925\n",
      "2\n",
      "12\n",
      "1\n",
      "Interest: Not interested!\n",
      "Face detected\n",
      "[[[[66 86 59]\n",
      "   [64 84 57]\n",
      "   [66 84 58]\n",
      "   ...\n",
      "   [35 31 22]\n",
      "   [37 33 23]\n",
      "   [38 34 22]]\n",
      "\n",
      "  [[65 85 58]\n",
      "   [64 84 57]\n",
      "   [67 85 59]\n",
      "   ...\n",
      "   [37 33 25]\n",
      "   [37 34 25]\n",
      "   [38 34 25]]\n",
      "\n",
      "  [[67 86 61]\n",
      "   [66 85 59]\n",
      "   [67 85 59]\n",
      "   ...\n",
      "   [38 36 30]\n",
      "   [39 36 30]\n",
      "   [39 37 28]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[66 79 62]\n",
      "   [66 79 62]\n",
      "   [65 78 60]\n",
      "   ...\n",
      "   [41 49 38]\n",
      "   [40 49 38]\n",
      "   [47 59 45]]\n",
      "\n",
      "  [[63 78 61]\n",
      "   [63 78 61]\n",
      "   [62 78 58]\n",
      "   ...\n",
      "   [38 47 34]\n",
      "   [41 51 37]\n",
      "   [50 61 46]]\n",
      "\n",
      "  [[59 77 59]\n",
      "   [58 77 58]\n",
      "   [58 74 56]\n",
      "   ...\n",
      "   [40 50 36]\n",
      "   [39 50 35]\n",
      "   [45 58 41]]]]\n",
      "result: -1.167723760008812, 2.5123625993728638\n",
      "Face detected\n",
      "[[[[66 84 62]\n",
      "   [66 84 62]\n",
      "   [68 86 62]\n",
      "   ...\n",
      "   [56 51 45]\n",
      "   [53 47 41]\n",
      "   [50 45 39]]\n",
      "\n",
      "  [[68 83 61]\n",
      "   [67 84 60]\n",
      "   [68 85 59]\n",
      "   ...\n",
      "   [56 52 44]\n",
      "   [53 49 41]\n",
      "   [50 46 38]]\n",
      "\n",
      "  [[67 83 59]\n",
      "   [68 84 58]\n",
      "   [68 85 59]\n",
      "   ...\n",
      "   [53 50 41]\n",
      "   [50 47 38]\n",
      "   [49 45 36]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[55 75 55]\n",
      "   [56 75 55]\n",
      "   [54 73 53]\n",
      "   ...\n",
      "   [37 47 56]\n",
      "   [34 44 52]\n",
      "   [31 44 51]]\n",
      "\n",
      "  [[59 76 57]\n",
      "   [60 76 57]\n",
      "   [57 74 55]\n",
      "   ...\n",
      "   [37 48 55]\n",
      "   [36 48 57]\n",
      "   [37 50 58]]\n",
      "\n",
      "  [[62 78 59]\n",
      "   [65 79 59]\n",
      "   [60 77 58]\n",
      "   ...\n",
      "   [34 46 53]\n",
      "   [35 50 57]\n",
      "   [36 50 58]]]]\n",
      "result: -0.5798852443695068, 1.6071653366088867\n",
      "STOP Thread\n",
      "Face detected\n",
      "[[[[68 84 62]\n",
      "   [67 82 61]\n",
      "   [69 83 61]\n",
      "   ...\n",
      "   [42 43 38]\n",
      "   [40 42 37]\n",
      "   [35 36 31]]\n",
      "\n",
      "  [[67 85 62]\n",
      "   [68 85 60]\n",
      "   [70 85 59]\n",
      "   ...\n",
      "   [39 41 38]\n",
      "   [38 40 37]\n",
      "   [37 37 34]]\n",
      "\n",
      "  [[64 84 57]\n",
      "   [68 87 59]\n",
      "   [71 87 60]\n",
      "   ...\n",
      "   [38 40 36]\n",
      "   [39 41 38]\n",
      "   [42 42 39]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[58 75 57]\n",
      "   [60 75 57]\n",
      "   [63 75 58]\n",
      "   ...\n",
      "   [27 32 18]\n",
      "   [47 53 37]\n",
      "   [64 72 55]]\n",
      "\n",
      "  [[62 76 59]\n",
      "   [61 74 58]\n",
      "   [61 73 56]\n",
      "   ...\n",
      "   [35 39 25]\n",
      "   [54 61 45]\n",
      "   [65 72 56]]\n",
      "\n",
      "  [[64 77 60]\n",
      "   [64 76 60]\n",
      "   [63 74 58]\n",
      "   ...\n",
      "   [35 41 27]\n",
      "   [52 59 44]\n",
      "   [60 69 53]]]]\n",
      "result: -0.34494202584028244, 3.26352059841156\n",
      "2\n",
      "15\n",
      "1\n",
      "Interest: Not interested!\n",
      "Close button pressed\n",
      "STOP Thread\n"
     ]
    }
   ],
   "source": [
    "# Create GUI with PyQt\n",
    "selected_window = \"\"\n",
    "\n",
    "class Ui_MainWindow(object): \n",
    "    def setupUi(self, window): \n",
    "        super().__init__()\n",
    "        self.window = window\n",
    "        #self.window.box_selection.addItems(inputList)\n",
    "        self.window.btn_start.clicked.connect(self.getSelection)\n",
    "        self.recording = False\n",
    "        self.totalResults = \"\"\n",
    "        #self.thread1 = ProcessStream(self.window.box_selection, window)\n",
    "        self.thread1 = ProcessStream()\n",
    "        self.thread1.output.connect(self.addResults)\n",
    "        app.aboutToQuit.connect(self.closeEvent)\n",
    "        \n",
    "    def getSelection(self): \n",
    "        if self.recording == False:\n",
    "            #selected_window = str(self.window.box_selection.currentText())\n",
    "            #print(\"Analytics got started! Selected window: \" + selected_window)\n",
    "            print(\"Analytics got started!\")\n",
    "            self.recording = True\n",
    "            # changing the text of label after button got clicked \n",
    "            self.window.btn_start.setText(\"Stop Analytics\")\n",
    "            self.thread1.start() # This actually causes the thread to run\n",
    "        else:\n",
    "            self.recording = False\n",
    "            self.thread1.stop()\n",
    "                        \n",
    "            self.window.btn_start.setText(\"Start Recording\")\n",
    "            # self.thread1 = ProcessStream(self.window.box_selection, self.window)  # recreate thread\n",
    "            self.thread1 = ProcessStream()\n",
    "            self.thread1.output.connect(self.addResults)\n",
    "    \n",
    "    def closeEvent(self):\n",
    "        print('Close button pressed')\n",
    "        self.recording = False\n",
    "        self.thread1.stop()\n",
    "        \n",
    "        if IPYTHON:\n",
    "            app.deleteLater\n",
    "        else:\n",
    "            sys.exit(0)\n",
    "    \n",
    "    def addResults(self, inputText):\n",
    "        self.totalResults = (inputText + \"\\n\" + self.totalResults)\n",
    "        self.window.box_results.setText(self.totalResults)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":  \n",
    "    app = QtWidgets.QApplication(sys.argv)  \n",
    "    window = uic.loadUi(\"dialog_2.ui\")\n",
    "    \n",
    "    myApp = Ui_MainWindow()  \n",
    "    # myApp.setupUi(window, getWindowNames())\n",
    "    myApp.setupUi(window)  \n",
    "      \n",
    "      \n",
    "    if IPYTHON == False:\n",
    "        window.show() \n",
    "        sys.exit(app.exec_())\n",
    "    else:\n",
    "        window.show()\n",
    "        app.exec_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
